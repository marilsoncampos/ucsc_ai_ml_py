{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My software product has these functions\n",
    "def second_larger_right(*numbers):\n",
    "    num_set = set(numbers)\n",
    "    if not len(num_set):\n",
    "        return None\n",
    "    biggest = max(num_set)\n",
    "    num_set.remove(biggest)\n",
    "    if not len(num_set):\n",
    "        return None\n",
    "    return max(num_set)\n",
    "\n",
    "def second_larger(*numbers):\n",
    "    num_set = set(numbers)\n",
    "    if len(num_set) < 2:\n",
    "        return None\n",
    "    num_set.remove(max(num_set))\n",
    "    return max(num_set)\n",
    "\n",
    "class MyProgramError(Exception):\n",
    "    pass\n",
    "\n",
    "def fake_invalid_params_call():\n",
    "    return\n",
    "    \n",
    "def real_invalid_params_call():\n",
    "    raise MyProgramError('I am broke!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCap(unittest.TestCase):\n",
    "\n",
    "    def test_naive_case(self):\n",
    "        self.fail(\"Not implemented\")\n",
    "\n",
    "    def test_no_num(self):\n",
    "        self.fail(\"Not implemented\")\n",
    "\n",
    "    def test_pair(self):\n",
    "        self.fail(\"Not implemented\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_naive_case (__main__.TestCap) ... FAIL\n",
      "test_no_num (__main__.TestCap) ... FAIL\n",
      "test_pair (__main__.TestCap) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_naive_case (__main__.TestCap)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1640/4004748248.py\", line 4, in test_naive_case\n",
      "    self.fail(\"Not implemented\")\n",
      "AssertionError: Not implemented\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_no_num (__main__.TestCap)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1640/4004748248.py\", line 7, in test_no_num\n",
      "    self.fail(\"Not implemented\")\n",
      "AssertionError: Not implemented\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_pair (__main__.TestCap)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1640/4004748248.py\", line 10, in test_pair\n",
      "    self.fail(\"Not implemented\")\n",
      "AssertionError: Not implemented\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.005s\n",
      "\n",
      "FAILED (failures=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0xffff96b89840>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['TestCap.test_naive_case'], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCap(unittest.TestCase):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(TestCap, self).__init__(*args, **kwargs)\n",
    "        self.logs = []\n",
    "\n",
    "    def setUp(self):\n",
    "        pass\n",
    "\n",
    "    def tearDown(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def test_naive_case(self):\n",
    "        expected = 3\n",
    "        result = second_larger(1,2,3,4)\n",
    "        self.logs.append((expected, result))\n",
    "        self.assertEqual(result, expected)\n",
    "\n",
    "    def test_no_num(self):\n",
    "        result = second_larger()\n",
    "        self.logs.append((None, result))\n",
    "        self.assertEqual(result, None)\n",
    "\n",
    "    def test_one_num(self):\n",
    "        result = second_larger(1)\n",
    "        self.logs.append((None, result))\n",
    "        self.assertEqual(result, None)\n",
    "\n",
    "    def test_pair(self):\n",
    "        result = second_larger(10, 1, 2)\n",
    "        self.logs.append((2, result))\n",
    "        self.assertEqual(result, 2)\n",
    "\n",
    "    @unittest.skip(\"Incomplete. Dont test yet.\")\n",
    "    def test_incomplete(self):\n",
    "        self.fail(\"shouldn't happen\")\n",
    "\n",
    "    def test_fake_failure(self):\n",
    "        with self.assertRaises(MyProgramError) as error:\n",
    "            fake_invalid_params_call()\n",
    "        self.assertTrue(type(error.exception) is MyProgramError)\n",
    "\n",
    "    def test_real_failure(self):\n",
    "        with self.assertRaises(MyProgramError) as error:\n",
    "            real_invalid_params_call()\n",
    "        self.assertTrue(type(error.exception) is MyProgramError)\n",
    "    \n",
    "    def test_close_values(self):\n",
    "        expected = 4.0\n",
    "        current = 4.002\n",
    "        threshold = 0.01\n",
    "        self.assertAlmostEqual(current, expected, delta=threshold)\n",
    "\n",
    "    def test_not_close_enough(self):\n",
    "        v1 = 4.00\n",
    "        v2 = 4.01\n",
    "        threshold = 0.001\n",
    "        self.assertAlmostEqual(v1, v2, delta=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_close_values (__main__.TestCap) ... ok\n",
      "test_fake_failure (__main__.TestCap) ... FAIL\n",
      "test_incomplete (__main__.TestCap) ... skipped 'Incomplete. Dont test yet.'\n",
      "test_naive_case (__main__.TestCap) ... ok\n",
      "test_no_num (__main__.TestCap) ... ok\n",
      "test_not_close_enough (__main__.TestCap) ... FAIL\n",
      "test_one_num (__main__.TestCap) ... ok\n",
      "test_pair (__main__.TestCap) ... ok\n",
      "test_real_failure (__main__.TestCap) ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_fake_failure (__main__.TestCap)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1640/237305369.py\", line 40, in test_fake_failure\n",
      "    with self.assertRaises(MyProgramError) as error:\n",
      "AssertionError: MyProgramError not raised\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_not_close_enough (__main__.TestCap)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1640/237305369.py\", line 59, in test_not_close_enough\n",
      "    self.assertAlmostEqual(v1, v2, delta=threshold)\n",
      "AssertionError: 4.0 != 4.01 within 0.001 delta (0.009999999999999787 difference)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.009s\n",
      "\n",
      "FAILED (failures=2, skipped=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0xffff96b8bd30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding negative tests and marking tests to be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCap(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        pass\n",
    "\n",
    "    def tearDown(self):\n",
    "        pass\n",
    "\n",
    "    def test_naive_case(self):\n",
    "        expected = 3\n",
    "        result = second_larger(1,2,3,4)\n",
    "        self.assertEqual(result, expected)\n",
    "\n",
    "    def test_no_num(self):\n",
    "        result = second_larger()\n",
    "        self.assertEqual(result, None)\n",
    "\n",
    "    def test_one_num(self):\n",
    "        result = second_larger(1)\n",
    "        self.assertEqual(result, None)\n",
    "\n",
    "    def test_pair(self):\n",
    "        result = second_larger(10, 1, 2)\n",
    "        self.assertEqual(result, 2)\n",
    "\n",
    "    @unittest.skip(\"Incomplete. Dont test yet.\")\n",
    "    def test_incomplete(self):\n",
    "        self.fail(\"shouldn't happen\")\n",
    "        \n",
    "    @unittest.expectedFailure\n",
    "    def test_fake_failure(self):\n",
    "        with self.assertRaises(MyProgramError) as error:\n",
    "            fake_invalid_params_call()\n",
    "        self.assertTrue(type(error.exception) is MyProgramError)\n",
    "\n",
    "    def test_real_failure(self):\n",
    "        with self.assertRaises(MyProgramError) as error:\n",
    "            real_invalid_params_call()\n",
    "        self.assertTrue(type(error.exception) is MyProgramError)\n",
    "    \n",
    "    def test_close_values(self):\n",
    "        expected = 4.0\n",
    "        current = 4.002\n",
    "        threshold = 0.01\n",
    "        self.assertAlmostEqual(current, expected, delta=threshold)\n",
    "\n",
    "    def test_not_close_enough(self):\n",
    "        v1 = 4.00\n",
    "        v2 = 4.01\n",
    "        threshold = 0.01\n",
    "        self.assertAlmostEqual(v1, v2, delta=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_close_values (__main__.TestCap) ... ok\n",
      "test_fake_failure (__main__.TestCap) ... expected failure\n",
      "test_incomplete (__main__.TestCap) ... skipped 'Incomplete. Dont test yet.'\n",
      "test_naive_case (__main__.TestCap) ... ok\n",
      "test_no_num (__main__.TestCap) ... ok\n",
      "test_not_close_enough (__main__.TestCap) ... ok\n",
      "test_one_num (__main__.TestCap) ... ok\n",
      "test_pair (__main__.TestCap) ... ok\n",
      "test_real_failure (__main__.TestCap) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.025s\n",
      "\n",
      "OK (skipped=1, expected failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0xffff9812ac20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
